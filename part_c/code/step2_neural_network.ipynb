{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "np.random.seed(1024) \n",
    "random.seed(2048)\n",
    "tf.random.set_seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('data/sc_training.h5ad')\n",
    "df = adata.obs[['condition', 'state']]\n",
    "prop = df.groupby(by=['condition', 'state'],as_index=False).size()\n",
    "total = df.groupby(by='condition',as_index=False).size()\n",
    "prop = prop.merge(total, on='condition', how='left')\n",
    "prop['prop'] = prop.size_x /prop.size_y\n",
    "prop = prop.pivot_table(index='condition', columns='state', values='prop')\n",
    "prop = prop[['progenitor', 'effector', 'terminal exhausted', 'cycling', 'other']]\n",
    "\n",
    "state_wt = np.array(prop.loc['Unperturbed'].values)\n",
    "test_set = ['Aqr', 'Bach2', 'Bhlhe40', 'Ets1', 'Fosb', 'Mafk', 'Stat3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(\n",
    "    input_size = 32,\n",
    "    output_size = 5,\n",
    "    size_dense = 8,\n",
    "    dropout_rate = 0.15,\n",
    "    l1 = 1e-3,\n",
    "    l2 = 1e-4,\n",
    "    learning_rate = 1e-3,\n",
    "    mae_weight=2\n",
    "):\n",
    "    def custom_KL_MAE_loss(y_true, y_pred):\n",
    "        y_true = tf.multiply(y_true, [1,1,1,1,0.01])\n",
    "        y_pred = tf.multiply(y_pred, [1,1,1,1,0.01])\n",
    "        kl = tf.keras.metrics.kl_divergence(y_true, y_pred)\n",
    "        mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n",
    "        return kl+mae*mae_weight\n",
    "    \n",
    "    input_layer = Input(shape=input_size)\n",
    "    x = Dense(size_dense, activation='relu', kernel_regularizer=regularizers.L1L2(l1,l2))(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(size_dense, activation='sigmoid', kernel_regularizer=regularizers.L1L2(l1,l2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss= custom_KL_MAE_loss, #\"kullback_leibler_divergence\",\n",
    "                  metrics=['mae']\n",
    "                 )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 32\n",
    "g_embed = np.load(f'submission/embedding/gene_embedding_{emb_size}.npy')\n",
    "g_name = np.load(f'submission/embedding/gene_names_{emb_size}.npy', allow_pickle= True)\n",
    "\n",
    "genes = list(set(prop.index.tolist()))\n",
    "training_conditions = [g for g in genes if g in g_name]\n",
    "\n",
    "#extract embedding of training set\n",
    "X, Y = [], []\n",
    "for g in training_conditions:\n",
    "    x = g_embed[list(g_name).index(g)]\n",
    "    y = np.array(prop.loc[g].values)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X_test = []\n",
    "for g in test_set:\n",
    "    x = g_embed[list(g_name).index(g)]\n",
    "    X_test.append(x)\n",
    "X_test = np.array(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train different model to map 32D gene embedding vector to 5D output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler on the whole gene list\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(g_embed)\n",
    "\n",
    "with open('./submission/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(X_scaler, f)\n",
    "\n",
    "#transform test set\n",
    "X_test_transformed = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=36\n",
    "epochs=2000\n",
    "\n",
    "X, Y = shuffle(X,Y,random_state=seed)\n",
    "kf = KFold(n_splits=10)\n",
    "kfold = kf.split(X, Y)\n",
    "\n",
    "for n_try in [4,5,6,7,8]:\n",
    "\n",
    "    score = []\n",
    "    predictions = []\n",
    "\n",
    "    for k, (train, val) in enumerate(kfold):\n",
    "        X_train, Y_train = X[train], Y[train]\n",
    "        X_val, Y_val = X[val], Y[val]\n",
    "\n",
    "        X_train_transformed = X_scaler.transform(X_train)\n",
    "        X_val_transformed = X_scaler.transform(X_val)\n",
    "\n",
    "        for dropout_rate in [0]:\n",
    "            for l1 in [1e-3, 1e-4,0]:\n",
    "                for l2 in [0, 1e-5]:\n",
    "                    for learning_rate in [1e-3]:\n",
    "\n",
    "                        #define lr schedule\n",
    "                        decay = learning_rate / (epochs-50) * 10                        \n",
    "                        def scheduler(epoch, lr):\n",
    "                            if epoch < 50:\n",
    "                                return lr\n",
    "                            else:\n",
    "                                return lr * 1/(1+decay*epoch) #tf.math.exp(-0.1)\n",
    "\n",
    "                        for mae_weight in [2]:\n",
    "                            for batch_size in [8,16]:\n",
    "                                model_path = f\"./submission/checkpoints/NN/model_{emb_size}_{dropout_rate}_{l1}_{l2}_{learning_rate}_{mae_weight}_{batch_size}_{k}_{n_try}.h5\"\n",
    "\n",
    "                                #define model\n",
    "                                model = regression_model(\n",
    "                                            input_size = emb_size,\n",
    "                                            output_size = 5,\n",
    "                                            size_dense = 8,\n",
    "                                            dropout_rate = dropout_rate,\n",
    "                                            l1 = l1,\n",
    "                                            l2 = l2,\n",
    "                                            learning_rate = learning_rate,\n",
    "                                            mae_weight=mae_weight\n",
    "                                        )\n",
    "\n",
    "                                #define callbacks\n",
    "                                checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                                    model_path,\n",
    "                                    monitor='val_mae', \n",
    "                                    verbose=0, save_best_only=True, mode='min'\n",
    "                                )\n",
    "                                early_stop = keras.callbacks.EarlyStopping(monitor='val_mae', patience=200, mode='min')\n",
    "                                schedule = keras.callbacks.LearningRateScheduler(scheduler, verbose=0)\n",
    "\n",
    "                                # training\n",
    "                                model.fit(X_train_transformed, Y_train, \n",
    "                                            # sample_weight=w, \n",
    "                                            epochs=epochs, \n",
    "                                            shuffle=True, \n",
    "                                            batch_size=batch_size,\n",
    "                                            validation_data=(X_val_transformed,Y_val),\n",
    "                                            callbacks = [checkpoint, early_stop, schedule],\n",
    "                                            verbose = 0\n",
    "                                            )\n",
    "\n",
    "                                # calculate best val_mae\n",
    "                                model.load_weights(model_path)\n",
    "                                mae_train = mean_absolute_error(Y_train, model.predict(X_train_transformed))\n",
    "                                mae_val = mean_absolute_error(Y_val, model.predict(X_val_transformed))\n",
    "\n",
    "                                # predict test genes\n",
    "                                Y_test_pred = model.predict(X_test_transformed)\n",
    "\n",
    "                                score.append([\n",
    "                                    n_try, k, dropout_rate, l1, l2, learning_rate, mae_weight, batch_size, mae_train, mae_val\n",
    "                                ])\n",
    "                                predictions.append(Y_test_pred)\n",
    "\n",
    "                                print(n_try, k, dropout_rate, l1, l2, learning_rate, mae_weight, batch_size, mae_train, mae_val)\n",
    "\n",
    "                                del model, model_path\n",
    "\n",
    "\n",
    "    score = pd.DataFrame(\n",
    "        score,\n",
    "        columns = [\"n_try\", \"k\", \"dropout_rate\", \"l1\", \"l2\", \"learning_rate\", \"mae_weight\", \"batch_size\", \"mae_train\", \"mae_val\"]\n",
    "    )\n",
    "    score.to_csv(f\"./submission/predictions/NN_emb32_score_try{n_try}.csv\")\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    np.save(f\"./submission/predictions/NN_emb32_prediction_try{n_try}\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "eeb8680eb43b9a87a49e32cc1c39b4f8c04117cd7cf42ba09bd4997cc8bf2498"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
